{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from bson import ObjectId\n",
    "import ast\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Create a MongoClient object and specify the MongoDB connection URL\n",
    "url = \"mongodb://localhost:27017/\"\n",
    "client = MongoClient(url)\n",
    "\n",
    "# Access a specific database\n",
    "db = client[\"YT_db\"]\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading twitter and the updated yt test collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_collection = db.tw_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_test_collection = db.yt_test_collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6471c55c3286bb1167a527bf'),\n",
       " 'id': '7A9D8QfCEKQ',\n",
       " 'lista_url': \"['https://youtu.be/7A9D8QfCEKQ']\",\n",
       " 'tweet_ids': ['1320856307394473984',\n",
       "  '1321399262551265280',\n",
       "  '1320914155566731265',\n",
       "  '1321000433779904517',\n",
       "  '1321616034999291904',\n",
       "  '1321400816218050560',\n",
       "  '1320810069714472966',\n",
       "  '1320810766711312387']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_test_collection.find_one()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving tweets text and hashtags associated to each test yt video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_video_tweets(yt_collection, tw_collection):\n",
    "    video_ids = yt_collection.find()  \n",
    "    i = 0\n",
    "    \n",
    "    for video in video_ids:\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "        i+=1\n",
    "        video_id = video[\"id\"] \n",
    "        \n",
    "        #tweet_ids_str = video.get(\"tweet_ids\", \"\")\n",
    "        #tweet_ids = ast.literal_eval(tweet_ids_str)\n",
    "\n",
    "        tweet_ids = video.get(\"tweet_ids\", \"\")\n",
    "\n",
    "        # Retrieve corresponding tweets from tw_collection\n",
    "        tweets = tw_collection.find(\n",
    "            {\"tweetid\": {\"$in\": tweet_ids}}, \n",
    "            {\"text\": 1, \"hashtag\": 1} \n",
    "        )\n",
    "\n",
    "        # Collect text and hashtag for each tweet\n",
    "        tweet_text = \" \"\n",
    "        for tweet in tweets:             \n",
    "            text = tweet.get(\"text\") \n",
    "            if len(text) > 4:\n",
    "                tweet_text += \" \" + text\n",
    "\n",
    "            hashtag = tweet.get(\"hashtag\")\n",
    "            if len(hashtag) > 4:\n",
    "                tweet_text += \" \" + hashtag\n",
    "\n",
    "        # Update the video document with the tweet_text field\n",
    "        yt_collection.update_one(\n",
    "            {\"id\": video_id},\n",
    "            {\"$set\": {\"tweet_text\": tweet_text}}\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "update_video_tweets(yt_collection=yt_test_collection, tw_collection=tw_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6471c55c3286bb1167a527bf'),\n",
       " 'id': '7A9D8QfCEKQ',\n",
       " 'lista_url': \"['https://youtu.be/7A9D8QfCEKQ']\",\n",
       " 'tweet_ids': ['1320856307394473984',\n",
       "  '1321399262551265280',\n",
       "  '1320914155566731265',\n",
       "  '1321000433779904517',\n",
       "  '1321616034999291904',\n",
       "  '1321400816218050560',\n",
       "  '1320810069714472966',\n",
       "  '1320810766711312387'],\n",
       " 'tweet_text': '  BIDEN FAMILY BUSINESS PARTNER \"TONY BOBULINSKI\" ENDS BIDEN LEGACY! https://t.co/8OlRTSK7pj via @YouTube @realDonaldTrump   Bring the rain.  https://t.co/g4XPjgssPL @TCscoops13 @cooper_m @realDonaldTrump Shocking stuff- Biden‚Äôs are as bad as the Clintons.. https://t.co/uNMBXdfC9G @tominkerry @SamCronin16 @cooper_m Biden‚Äôs are as bad as the Clintons, corrupt as fluck https://t.co/uNMBXdfC9G https://t.co/WNvpwHaVO8 Tony B. re Biden BIDEN FAMILY BUSINESS PARTNER \"TONY BOBULINSKI\" ENDS BIDEN LEGACY! https://t.co/J9JRIcpsEG via @YouTube RT @kunkelKAG: BIDEN FAMILY BUSINESS PARTNER \"TONY BOBULINSKI\" ENDS BIDEN LEGACY! https://t.co/J9JRIcpsEG via @YouTube BIDEN FAMILY BUSINESS PARTNER \"TONY BOBULINSKI\" ENDS BIDEN LEGACY! üî• https://t.co/CHrwfxjIPu üî• This Is Bad News for the ‚ÄúBidens‚Äù !!! üßê@CNN @cnnbrk @CNNPolitics @cnni @CNNent https://t.co/LSgwy0jHQX'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_test_collection.find_one()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving as a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection data saved as JSON.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Custom JSON encoder class to handle ObjectId serialization\n",
    "class JSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, ObjectId):\n",
    "            return str(o)\n",
    "        return super().default(o)\n",
    "\n",
    "# Retrieve all documents from the collection\n",
    "all_documents = list(yt_test_collection.find())\n",
    "\n",
    "# Specify the path and filename for the output JSON file\n",
    "output_file = \"yt_collection_test_text.json\"\n",
    "\n",
    "# Save the collection data to the JSON file\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(all_documents, file, cls=JSONEncoder,indent=4)\n",
    "\n",
    "print(\"Collection data saved as JSON.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all documents from the collection\n",
    "cursor = yt_test_collection.find()\n",
    "\n",
    "# Convert the cursor to a DataFrame\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# Specify the columns to include in the CSV file\n",
    "columns = ['id', 'tweet_ids', 'tweet_text']\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('merged_yt_collection_test_text.csv', columns=columns, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove the punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [token.translate(table) for token in tokens if token.isalpha()]\n",
    "\n",
    "    # Remove the English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Using a word Lemmatizer \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_text'] = df['tweet_text'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving as a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"merged_yt_collection_test_preprocessedtxt.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_twitter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
