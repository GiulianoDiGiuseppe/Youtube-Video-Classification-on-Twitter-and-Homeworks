{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and connection to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from bson import ObjectId\n",
    "\n",
    "# Create a MongoClient object and specify the MongoDB connection URL\n",
    "url = \"mongodb://localhost:27017/\"\n",
    "client = MongoClient(url)\n",
    "\n",
    "# Access a specific database\n",
    "db = client[\"YT_db\"]\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading previously created twitter collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_collection = db.tw_collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating collection for the test youtube videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_test_collection = db.yt_test_collection\n",
    "\n",
    "with open('y_test.csv', 'r') as file:\n",
    "    csv_data = csv.DictReader(file)\n",
    "    for row in csv_data:\n",
    "        yt_test_collection.insert_one(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching each yt video to the list of referring tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/2\n",
      "Processed batch 2/2\n",
      "Matching tweet_ids updated in yt_collection.\n",
      "id_tweet_ids saved to file.\n"
     ]
    }
   ],
   "source": [
    "# Collect all id values from yt_test_collection\n",
    "id_values = [doc['id'] for doc in yt_test_collection.find({}, {'id': 1})]\n",
    "# Define the batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Split id_values into batches\n",
    "id_batches = [id_values[i:i+batch_size] for i in range(0, len(id_values), batch_size)]\n",
    "\n",
    "# Create a dictionary to store the matching tweet_ids for each id\n",
    "id_tweet_ids = {id_val: set() for id_val in id_values}\n",
    "\n",
    "# Iterate over each batch and collect the matching tweet_ids\n",
    "for batch_index, id_batch in enumerate(id_batches):\n",
    "    pattern = \"|\".join(map(re.escape, id_batch))\n",
    "\n",
    "    # Find documents in tw_collection where expanded_url contains any of the id values in the batch\n",
    "    results = tw_collection.find(\n",
    "        {\"expanded_url\": {\"$elemMatch\": {\"$regex\": pattern}}},\n",
    "        {\"tweetid\": 1, \"expanded_url\": 1}\n",
    "    )\n",
    "   \n",
    "    # Update id_tweet_ids dictionary with the matching tweet_ids\n",
    "    for doc in results:\n",
    "        tweet_id = doc[\"tweetid\"]\n",
    "        expanded_url_list = doc[\"expanded_url\"]\n",
    "        for expanded_url in expanded_url_list:\n",
    "            for id_val in id_batch:\n",
    "                if id_val in expanded_url:\n",
    "                    id_tweet_ids[id_val].add(tweet_id)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Processed batch {batch_index+1}/{len(id_batches)}\")\n",
    "\n",
    "    # Update yt_collection with the tweet_ids for each id\n",
    "for id_val, tweet_ids in id_tweet_ids.items():\n",
    "    yt_test_collection.update_one(\n",
    "        {\"id\": id_val},\n",
    "        {\"$set\": {\"tweet_ids\": list(tweet_ids)}}\n",
    "    )\n",
    "\n",
    "# Print completion message\n",
    "print(\"Matching tweet_ids updated in yt_collection.\")\n",
    "\n",
    "id_tweet_ids_list = {k: list(v) for k, v in id_tweet_ids.items()}\n",
    "\n",
    "# Save id_tweet_ids to a file\n",
    "with open(\"id_tweet_test_ids.json\", \"w\") as file:\n",
    "    json.dump(id_tweet_ids_list, file)\n",
    "\n",
    "print(\"id_tweet_ids saved to file.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the test collection to a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom JSON encoder class to handle ObjectId serialization\n",
    "class JSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, ObjectId):\n",
    "            return str(o)\n",
    "        return super().default(o)\n",
    "\n",
    "# Retrieve all documents from the collection\n",
    "all_documents = list(yt_test_collection.find())\n",
    "\n",
    "# Specify the path and filename for the output JSON file\n",
    "output_file = \"y_test_collection.json\"\n",
    "\n",
    "# Save the collection data to the JSON file\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(all_documents, file, cls=JSONEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6471c55c3286bb1167a527bf'),\n",
       " 'id': '7A9D8QfCEKQ',\n",
       " 'lista_url': \"['https://youtu.be/7A9D8QfCEKQ']\",\n",
       " 'tweet_ids': ['1320856307394473984',\n",
       "  '1321399262551265280',\n",
       "  '1320914155566731265',\n",
       "  '1321000433779904517',\n",
       "  '1321616034999291904',\n",
       "  '1321400816218050560',\n",
       "  '1320810069714472966',\n",
       "  '1320810766711312387']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_test_collection.find_one()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_twitter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
