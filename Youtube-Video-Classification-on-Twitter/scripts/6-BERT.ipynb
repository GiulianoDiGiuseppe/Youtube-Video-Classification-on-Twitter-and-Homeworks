{"cells":[{"cell_type":"markdown","metadata":{"id":"ya0JPhh4Puex"},"source":["# Import libraries"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5-RGcjaXYTxS","executionInfo":{"status":"ok","timestamp":1685462293265,"user_tz":-120,"elapsed":12814,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}},"outputId":"182f9cd4-46f3-4057-b221-af4219d37594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIdXEMmsICPH"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import json\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlruiLVaQGhp","executionInfo":{"status":"ok","timestamp":1685462327329,"user_tz":-120,"elapsed":20371,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}},"outputId":"1c523f77-4978-4baf-8a09-7a28097b9b92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"CTApJYCFPue4"},"source":["# Upload csv, extract the text input feature and the target variable y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfsgccF5j8Nw"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/BDE/BERT/merged_yt_collection_preprocessedtxt.csv\")\n","text = df[\"preprocessed_text\"].to_numpy()\n","y = df[\"moderationStatus\"].to_numpy()"]},{"cell_type":"markdown","metadata":{"id":"ySrC5tJ7Pue7"},"source":["# Train and test split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIsm8d7iTdn2"},"outputs":[],"source":["test_size = 0.2\n","X_train,X_test,Y_train,Y_test = train_test_split(text,y,test_size=test_size,random_state=42,stratify = y)"]},{"cell_type":"markdown","metadata":{"id":"liXSMoHjPue7"},"source":["# Compiling and training of the model"]},{"cell_type":"code","source":["X_train_list = list(X_train)\n","Y_train_list = list(Y_train)"],"metadata":{"id":"r6hRVzMdYwJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set device (GPU if available, otherwise CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = 'bert-base-uncased'\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","# Load and preprocess the data\n","train_texts = X_train_list   # List of training texts\n","train_labels = Y_train_list  # List of corresponding training labels (0 or 1)\n","\n","def preprocess(texts, labels):\n","    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","    labels = torch.tensor(labels).to(device)\n","    return inputs, labels\n","\n","train_inputs, train_labels = preprocess(train_texts, train_labels)\n","train_data = list(zip(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels))\n","train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","\n","# Fine-tuning parameters\n","epochs = 3\n","learning_rate = 2e-5\n","\n","# Set model to training mode\n","model.train()\n","\n","# Initialize optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# Fine-tuning loop\n","for epoch in range(epochs):\n","    total_loss = 0\n","\n","    for batch in train_dataloader:\n","        optimizer.zero_grad()\n","        input_ids, attention_mask, labels = [tensor.to(device) for tensor in batch]\n","\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch+1}: Average Loss = {average_loss}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObM9U_cBX4lO","executionInfo":{"status":"ok","timestamp":1685467944101,"user_tz":-120,"elapsed":4104311,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}},"outputId":"e539de98-9400-4808-da88-b11b4bd72331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Average Loss = 0.48377565257990235\n","Epoch 2: Average Loss = 0.4317950873941079\n","Epoch 3: Average Loss = 0.3509556978697538\n"]}]},{"cell_type":"code","source":["# Save the fine-tuned model\n","model.save_pretrained('/content/drive/MyDrive/BDE/Models/fine-tuned-bert')\n","\n","# Load the fine-tuned model\n","loaded_model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/BDE/Models/fine-tuned-bert')"],"metadata":{"id":"9WQ3zLynfzYN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-mDG2tGNPue8"},"source":["# Evaluating the model"]},{"cell_type":"code","source":["input_inputs, _ = preprocess(list(X_test), [])  # Pass empty labels as we won't use them for inference\n","input_data = list(zip(input_inputs['input_ids'], input_inputs['attention_mask']))\n","input_dataloader = DataLoader(input_data, batch_size=16, shuffle=False)"],"metadata":{"id":"1vSaYbIJuq8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fv-anoEyutED","executionInfo":{"status":"ok","timestamp":1685468416567,"user_tz":-120,"elapsed":586,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}},"outputId":"e9d4542a-02c9-4858-d9a6-01ff4286a6aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["input_predictions = []\n","loaded_model = loaded_model.to(device)\n","with torch.no_grad():\n","    for batch in input_dataloader:\n","        input_ids, attention_mask = batch\n","        inputs = {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device)}\n","\n","        outputs = loaded_model(**inputs)\n","        logits = outputs.logits\n","\n","        predicted_labels = torch.max(logits, dim=1).indices\n","\n","        input_predictions.extend(predicted_labels.cpu().numpy())\n","\n","input_predictions = np.array(input_predictions)"],"metadata":{"id":"zXYKxqHluu71"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DidhPoEhxYOI","executionInfo":{"status":"ok","timestamp":1685468927066,"user_tz":-120,"elapsed":387,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}},"outputId":"8a8befaa-3399-4ec9-e53f-4c994a2f1eb7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 1, 0])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKXtKi9EaWJp","outputId":"d4cbef6d-e942-492a-9938-49b80818fa29","executionInfo":{"status":"ok","timestamp":1685468947550,"user_tz":-120,"elapsed":336,"user":{"displayName":"Alessandro Vanacore","userId":"09998057395511632102"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Macro f1-score: 0.6812267310214712\n"]}],"source":["\n","macro_f1_score = f1_score(Y_test,input_predictions,average=\"macro\")\n","print(f\"Macro f1-score: {macro_f1_score}\")"]},{"cell_type":"markdown","metadata":{"id":"zyM4cDpyPue9"},"source":["# Save model"]},{"cell_type":"markdown","metadata":{"id":"ieEvPEz2Pue9"},"source":["# Predict on test set"]},{"cell_type":"code","source":["path_test = \"/content/drive/MyDrive/BDE/Filtered_collections/y_test_collection.json\"\n","csv_test_path  = \"/content/drive/MyDrive/BDE/Predictions/y_test.csv\"\n","\n","with open(path_test, 'r') as test_file:\n","    test_json = json.load(test_file)\n","\n","df_test= pd.read_csv(csv_test_path)"],"metadata":{"id":"tcDbpxv-UPyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESMpk_BjPue9"},"outputs":[],"source":["df_test_text = pd.read_csv(\"/content/drive/MyDrive/BDE/RNN/merged_yt_collection_test_preprocessedtxt.csv\")\n","text_test = df_test_text[\"preprocessed_text\"].to_numpy()"]},{"cell_type":"code","source":["input_inputs, _ = preprocess(list(text_test), [])  # Pass empty labels as we won't use them for inference\n","input_data = list(zip(input_inputs['input_ids'], input_inputs['attention_mask']))\n","input_dataloader = DataLoader(input_data, batch_size=16, shuffle=False)"],"metadata":{"id":"8hmy3ZmXyG_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loaded_model.eval()"],"metadata":{"id":"PX5r1hREyK7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_predictions_test = []\n","loaded_model = loaded_model.to(device)\n","with torch.no_grad():\n","    for batch in input_dataloader:\n","        input_ids, attention_mask = batch\n","        inputs = {'input_ids': input_ids.to(device), 'attention_mask': attention_mask.to(device)}\n","\n","        outputs = loaded_model(**inputs)\n","        logits = outputs.logits\n","\n","        predicted_labels = torch.max(logits, dim=1).indices\n","\n","        input_predictions_test.extend(predicted_labels.cpu().numpy())\n","\n","input_predictions_test = np.array(input_predictions_test)"],"metadata":{"id":"rDIocfkyyO9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test[\"moderationStatus\"] =  np.where(input_predictions_test == 0, \"not moderated\", \"moderated\") \n","df_test.to_csv(f\"/content/drive/MyDrive/BDE/Predictions/BERT_model_{macro_f1_score:.10f}_y.csv\",index=False)"],"metadata":{"id":"lB-4SeNJUHsq"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}