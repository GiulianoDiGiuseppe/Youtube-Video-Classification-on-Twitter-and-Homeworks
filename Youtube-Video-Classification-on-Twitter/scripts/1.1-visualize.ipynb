{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "from bson import ObjectId\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a MongoClient object and specify the MongoDB connection URL\n",
    "url = \"mongodb://localhost:27017/\"\n",
    "client1 = MongoClient(url)\n",
    "\n",
    "# Access a specific database\n",
    "db1 = client1[\"youtube_twitter_db1\"]\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client1.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_collection = db1.tw_collection\n",
    "yt_collection = db1.yt_collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating to each tweet a label 1 if it refers to a moderated video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all tweet IDs linked to moderated videos\n",
    "moderated_tweet_ids = []\n",
    "for doc in yt_collection.find({'moderationStatus': 'moderated'}, {'tweet_ids': 1}):\n",
    "    moderated_tweet_ids.extend(doc['tweet_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "moderated_tweet_ids = list((set(moderated_tweet_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over documents in tw_collection\n",
    "for doc in tw_collection.find():\n",
    "    tweet_id = doc['tweetid']\n",
    "    moderated = 1 if tweet_id in moderated_tweet_ids else 0\n",
    "\n",
    "    # Update the document in tw_collection with the moderated field\n",
    "    tw_collection.update_one(\n",
    "        {'_id': doc['_id']},\n",
    "        {'$set': {'moderated': moderated}}\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save collection as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection data saved as JSON.\n"
     ]
    }
   ],
   "source": [
    "# Custom JSON encoder class to handle ObjectId serialization\n",
    "class JSONEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, ObjectId):\n",
    "            return str(o)\n",
    "        return super().default(o)\n",
    "\n",
    "# Retrieve all documents from the collection\n",
    "all_documents = list(tw_collection.find())\n",
    "\n",
    "# Specify the path and filename for the output JSON file\n",
    "output_file = \"tw_collection_w_status.json\"\n",
    "\n",
    "# Save the collection data to the JSON file\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(all_documents, file, cls=JSONEncoder)\n",
    "\n",
    "print(\"Collection data saved as JSON.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Retrieve documents from the collection\n",
    "cursor = tw_collection.find()\n",
    "\n",
    "# Convert documents to DataFrame\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(\"tw_collection_w_status.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_twitter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
